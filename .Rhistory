png("FigBarplot.png")
barplot(x)
dev.off()
x=c(2,5,4,3,4)
names(x)=c("A","B","C","D","E")
#save it as png file
png("FigBarplot.png")
barplot(x)
dev.off()
#create a vector
male=c(0,0,1,0,1,1)
male
#Change it into a facor vector
Fmale=factor(male,labels=c("female","male"))
Fmale
# Create a vector of rating scale
rating=c(3,1,2,2,3,1,1)
rating
Frating=factor(rating,labels=c("good","okay","bad"))
Frating
cov(x,y) # covariance between  x and y
cor(x,y) # correlation between x and y
x=c(2,5,4,3,4)
y=c(3,6,5,6,10)
#Fit a line
M1=lm(y~x)
coef(M1)
#get aplot
plot(x,y,pch=16,main="Scatter Plot")
# add a fitted line
abline(M1)
x=c(2,5,4,3,4)
y=c(3,6,5,6,10)
#Fit a line
M1=lm(y~x)
coef(M1)
#get aplot
plot(x,y,pch=16,main="Scatter Plot")
# add a fitted line
abline(M1)
text(3,7,"yhat=1.846+1.154x")
# Save it as png file
png("Fig1.png")
plot(x,y,pch=16,main="Scatter Plot")
# add a fitted line
abline(M1)
text(3,7,"yhat=1.846+1.154x")
dev.off()
x
y
plot(y~x)
legend("topleft","POINTS")
plot(y~x,main="PLOT OF POINTS")
library(lattice)
example(barchart)
render("geo.Rmd",html_document(toc=TRUE,number_sections=TRUE))
require(rmarkdown)
render("geo.Rmd",html_document(toc=TRUE,number_sections=TRUE))
render("geo.Rmd",html_document(toc=TRUE,number_sections=TRUE))
render("geo.Rmd",pdf_document(toc=TRUE,number_sections=TRUE))
require(knitr)
kable(DF1,caption="Data Frame with kable")
require(rstanarm)
# Fit model for wtstack data
names(wtstack)
M1=stan_glm(weight~women,data=wtstack)
require(rstanarm)
# Fit model for wtstack data
names(wtstack)
M1=stan_glm(weight~women,data=wtstack)
args(posterior_interval)
help("posterior_interval")
#get predictive interval
plot(predictive_interval(M1,prob=0.95))
Calcium=read.table("Calcium.txt",header=TRUE)
str(Calcium)
render("geo.Rmd",html_document(toc=TRUE,number_sections=TRUE))
require(rmarkdown)
render("geo.Rmd",html_document(toc=TRUE,number_sections=TRUE))
render("geo.Rmd",pdf_document(toc=TRUE,number_sections=TRUE))
render("geo.Rmd",pdf_document(toc=TRUE,number_sections=TRUE))
render("geo.Rmd",pdf_document(toc=TRUE,number_sections=TRUE))
render("geo.Rmd",pdf_document(toc=TRUE,number_sections=TRUE))
render("geo.Rmd",pdf_document(toc=TRUE,number_sections=TRUE))
render("geo.Rmd",html_document(toc=TRUE,number_sections=TRUE))
render("geo.Rmd",html_document(toc=TRUE,number_sections=TRUE))
pp_check(Mcalc)
pp_check(Mcalc)
render("geo.Rmd",html_document(toc=TRUE,number_sections=TRUE))
render("geo.Rmd",html_document(toc=TRUE,number_sections=TRUE))
render("geo.Rmd",pdf_document(toc=TRUE,number_sections=TRUE))
render("geo.Rmd",pdf_document(toc=TRUE,number_sections=TRUE))
render("geo.Rmd",pdf_document(toc=TRUE,number_sections=TRUE))
render("geo.Rmd",pdf_document(toc=TRUE,number_sections=TRUE))
render("geo.Rmd",pdf_document(toc=TRUE,number_sections=TRUE))
render("geo.Rmd",pdf_document(toc=TRUE,number_sections=TRUE))
render("geo.Rmd",html_document(toc=TRUE,number_sections=TRUE))
out1=TukeyHSD(calaov,which="Concentration")
out1
plot(out1)
require(brinla)
data(usair)
write.table(usair,file="usair.txt")
usair=read.table("usair.txt",header=TRUE)
names(usair)
dim(usair)
data(painrelief)
write.table(painrelief,file="painrelief.txt")
data(frencheconomy)
write.table(frencheconomy,file="frencheconomy.txt")
data(nzunemploy)
write.table(nzunemploy,file="nzunemploy.txt")
data(lowbwt)
write.table(lowbwt,file="lowbwt.txt")
data(AIDS)
write.table(AIDS,file="AIDS.txt")
data(crab)
write.table(crab,file="crab.txt")
require(MASS)
data(Insurance)
write.table(Insurance,file="Insurance.txt")
require(faraway)
data(wafer)
write.table(wafer,file="wafer.txt")
library(betareg)
install.packages("betareg")
require(betareg)
data(GasolineYield)
write.table(GasolineYield,file="GasolineYield.txt")
data(articles)
write.table(articles,file="articles.txt")
data(reeds)
write.table(reeds,file="reeds.txt")
data(reading)
write.table(reading,file="reading.txt")
data(meatspec)
write.table(meatspec,file="meatspec.txt")
age1=wooldridge::wage1
names(wage1)
wage1=wooldridge::wage1
names(wage1)
help(brinla::usair)
help(usair,package="brinla")
require(brinla)
data(usair)
names(usair)
M1usair=lm(SO2~.,data=usair)
summary(M1usair)
names(usair)
summary(M1usair)$coef
M1step=stepAIC(M1usair,trace=FALSE)
M1step=stepAIC(M1usair,trace=FALSE)
M1step$anova
q()
render("geo.Rmd",html_document(toc=TRUE,number_sections=TRUE))
render("geo.Rmd",html_document(toc=TRUE,number_sections=TRUE))
require(rmarkdown)
render("geo.Rmd",html_document(toc=TRUE,number_sections=TRUE))
render("geo.Rmd",pdf_document(toc=TRUE,number_sections=TRUE))
render("geo.Rmd",word_document(toc=TRUE,number_sections=TRUE))
render("geo.Rmd",word_document(toc=TRUE,number_sections=TRUE))
render("geo.Rmd",word_document(toc=TRUE))
q()
rmarkdown::render("geo.Rmd",html_document(toc=TRUE, number_sections=TRUE))
rmarkdown::render("geo.Rmd",html_document(toc=TRUE, number_sections=TRUE))
require(rmarkdown)
rmarkdown::render("geo.Rmd",html_document(toc=TRUE, number_sections=TRUE))
## Factorial experiment with 2 factors in RBD
painrelief=read.table("painrelief.txt",header=TRUE)
#create factor variables
painrelief=read.table("painrelief.txt",header=TRUE)
painrelief$Accupunture=as.factor(painrelief$Accupunture)
painrelief$Accupuncture=as.factor(painrelief$Accupunture)
painrelief$Accupuncture=as.factor(painrelief$Accupuncture)
#create factor variables
painrelief=read.table("painrelief.txt",header=TRUE)
painrelief$PainLevel=as.factor(painrelief$PainLevel)
painrelief$Codeine=as.factor(painrelief$Codeine)
painrelief$Acupuncture=as.factor(painrelief$Acupuncture)
# Fit the model
M2pain=lm(Relief~PainLevel+Codeine*Acupuncture,data=painrelief)
summary(M2pain)
render("geo.Rmd",html_document(toc=TRUE,number_sections=TRUE))
render("geo.Rmd",html_document(toc=TRUE,number_sections=TRUE))
## Look into graphics---`plot.design` and `boxplot`
```{r}
plot.design(painrelief)
```
## Look into graphics---`plot.design` and `boxplot`
```{r}
plot.design(painrelief,las=2)
```
render("geo.Rmd",html_document(toc=TRUE,number_sections=TRUE))
When predictors are highly correlated the problem of multicollinearity arises in which `se(beta)` gets inflated or unstable. We take data `frencheconomy` in which `IMPORT` is the response and predictors are domestic produnction (`DOPROD`), stock formation (`STOCK`), and domestic consumption (`CONSUM`). Let us see the data
```{r}
data(frencheconomy, package="brinla")
head(frencheconomy)
```
When predictors are highly correlated the problem of multicollinearity arises in which `se(beta)` gets inflated or unstable. We take data `frencheconomy` in which `IMPORT` is the response and predictors are domestic produnction (`DOPROD`), stock formation (`STOCK`), and domestic consumption (`CONSUM`). Let us see the data
```{r}
data(frencheconomy, package="brinla")
head(frencheconomy,n=4)
```
```{r,message=FALSE}
data(frencheconomy, package="brinla")
head(frencheconomy,n=4)
#get the correlation matrix among predictors third to fifth columns
cor(frencheconomy[,c(3,4,5)])
```
```{r,message=FALSE}
data(frencheconomy, package="brinla")
head(frencheconomy,n=4)
#get the correlation matrix among predictors third to fifth columns
cor(frencheconomy[,c(3,4,5)])
```
```{r,message=FALSE}
data(frencheconomy, package="brinla")
head(frencheconomy,n=4)
#get the correlation matrix among predictors third to fifth columns
cor(frencheconomy[,c(3,4,5)])
```
See the high correlation between `DOPROD` and `CONSUM`. This will cause the problem of multicollinearity. First we scale the data
```{r}
fe.scale=cbind(frencheconomy[,1:2],frencheconomy[,c(-1,-2)])
```
```{r,message=FALSE}
data(frencheconomy, package="brinla")
head(frencheconomy,n=4)
#get the correlation matrix among predictors third to fifth columns
cor(frencheconomy[,c(3,4,5)])
```
See the high correlation between `DOPROD` and `CONSUM`. This will cause the problem of multicollinearity. First we scale the data
```{r,message=FALSE}
fe.scale=cbind(frencheconomy[,1:2],frencheconomy[,c(-1,-2)])
head(fe.scale)
```
```{r,message=FALSE}
data(frencheconomy, package="brinla")
head(frencheconomy,n=4)
#get the correlation matrix among predictors third to fifth columns
cor(frencheconomy[,c(3,4,5)])
```
See the high correlation between `DOPROD` and `CONSUM`. This will cause the problem of multicollinearity. First we scale the data
```{r,message=FALSE}
fe.scale=cbind(frencheconomy[,1:2],scale(frencheconomy[,c(-1,-2)]))
head(fe.scale)
```
```{r,message=FALSE}
data(frencheconomy, package="brinla")
head(frencheconomy,n=4)
#get the correlation matrix among predictors third to fifth columns
cor(frencheconomy[,c(3,4,5)])
```
See the high correlation between `DOPROD` and `CONSUM`. This will cause the problem of multicollinearity. First we scale the data
```{r,message=FALSE}
fe.scaled=cbind(frencheconomy[,1:2],scale(frencheconomy[,c(-1,-2)]))
head(fe.scale)
```
We fit this data now
```{r,message=FALSE}
library(MASS)
ridge2=lm.ridge(IMPORT~DOPROD+STOCK+CONSUM,data=fe.scaled, lambda=seq(0,1,length=100))
ridge2.final=lm.ridge(IMPORT~DOPROD+STOCK+CONSUM,data=fe.scaled,lambda=reg2$kHKB)
ridge2.final
```
```{r,message=FALSE}
data(frencheconomy, package="brinla")
head(frencheconomy,n=4)
#get the correlation matrix among predictors third to fifth columns
cor(frencheconomy[,c(3,4,5)])
```
See the high correlation between `DOPROD` and `CONSUM`. This will cause the problem of multicollinearity. First we scale the data
```{r,message=FALSE}
fe.scaled=cbind(frencheconomy[,1:2],scale(frencheconomy[,c(-1,-2)]))
head(fe.scale)
```
We fit this data now
```{r,message=FALSE}
library(MASS)
ridge2=lm.ridge(IMPORT~DOPROD+STOCK+CONSUM,data=fe.scaled, lambda=seq(0,1,length=100))
ridge2.final=lm.ridge(IMPORT~DOPROD+STOCK+CONSUM,data=fe.scaled,lambda=reg2$kHKB)
ridge2.final
```
require(rmarkdown)
render("geo.Rmd",pdf_document(toc=TRUE,number_sections=TRUE))
This is case when erros are correlated, example is time series data. In this situation $\sigma^{2}I$ is replaced by $\Sigma$ which leads to generalized least sqaures. The function `gls` in the package **nlme** is used to model such data.
```{r}
require(brinla)
data(nzunemployment)
```
This is case when erros are correlated, example is time series data. In this situation $\sigma^{2}I$ is replaced by $\Sigma$ which leads to generalized least sqaures. The function `gls` in the package **nlme** is used to model such data.
```{r}
require(brinla)
data(nzunemployment)
```
This is case when erros are correlated, example is time series data. In this situation $\sigma^{2}I$ is replaced by $\Sigma$ which leads to generalized least sqaures. The function `gls` in the package **nlme** is used to model such data.
```{r}
require(brinla)
data(nzunemployment)
```
```{r}
require(brinla)
data(nzunemployment)
```
require(brinla)
data(nzunemploy)
```
```{r}
require(brinla)
data(nzunemploy,package="brinla")
```
```{r}
require(brinla)
data(nzunemploy,package="brinla")
```
require(brinla)
data(nzunemploy,package="brinla")
nzunemploy$centeredadult=with(nzunemploy,adult-mean(adult))
require(nlme)
nzunemploy.gls<-gls(youth~centeradult*policy,correlation=corAR1(form=~1),data=nzunemploy)
nzunemploy.gls<-gls(youth~centeredadult*policy,correlation=corAR1(form=~1),data=nzunemploy)
summary(nzunemploy.gls)
help(gls)
require(brinla)
data(lowbwt,package="brinla")
head(lowbwt)
str(lowbwt)
lowbwt$RACE=factor(lowbwt$RACE,labels = c("white","black","other"))
head(lowbwt)
lowbwt$SMOKE=factor(lowbwt$SMOKE,labels=c("no","yes"))
require(brinla)
data(lowbwt,package="brinla")
head(lowbwt)
str(lowbwt)
lowbwt$RACE=factor(lowbwt$RACE,labels = c("white","black","other"))
lowbwt$SMOKE=factor(lowbwt$SMOKE,labels=c("no","yes"))
lowbwt$HT=factor(lowbwt$HT,labels=c("no","yes"))
lowbwt$UI=factor(lowbwt$UI,labels=c("no","yes"))
require(brinla)
data(lowbwt,package="brinla")
head(lowbwt)
str(lowbwt)
lowbwt$RACE=factor(lowbwt$RACE,labels = c("white","black","other"))
lowbwt$SMOKE=factor(lowbwt$SMOKE,labels=c("no","yes"))
lowbwt$HT=factor(lowbwt$HT,labels=c("no","yes"))
lowbwt$UI=factor(lowbwt$UI,labels=c("no","yes"))
str(lowbwt)
M1low=glm(LOW~AGE+LWT+RACE+SMOKE+HT+UI+FTV,data=lowbwt,family=binomial())
round(coef(summary(M1low)),3)
require(arm)
coefplot(M1low)
opar=par(mar=c(4,10,4,2))
require(arm)
opar=par(mar=c(4,10,4,2))
coefplot(M1low)
par(opar)
require(arm)
opar=par(mar=c(4,10,4,2))# set margins of the figure
coefplot(M1low)
par(opar)# return to the original settings
require(arm)
opar=par(mar=c(4,10,4,2))# set margins of the figure
coefplot(M1low)
par(opar)# return to the original settings
Calcium=read.table("Calcium.txt",header=TRUE)
coefplot(calcaov)
Calcium=read.table("Calcium.txt", header=TRUE)
names(Calcium)
# Fit a model
calaov=aov(Length~Concentration, data=Calcium)
summary(calaov)
coefplot(calcaov)
Calcium=read.table("Calcium.txt", header=TRUE)
names(Calcium)
# Fit a model
calaov=aov(Length~Concentration, data=Calcium)
summary(calaov)
coefplot(calaov)
require(arm)
coefplot(calaov)
M2pain=lm(Relief~PainLevel+Codeine*Acupuncture,data=painrelief)
summary(M2pain)
require(arm)
coefplot(M2pain)
require(arm)
coefplot(M2pain)
require(brinla)
data(AIDS)
data(AIDS,package="brinla")
str(AIDS)
require(brinla)
data(AIDS,package="brinla")
str(AIDS)
opar=par(mfrow=c(1,2))
plot(DEATHS~TIME, data=AIDS)
hist(AIDS$DEATHS,xlab = "DEATHS")
par(opar)
opar=par(mfrow=c(1,2))
plot(DEATHS~TIME, data=AIDS,main="")
hist(AIDS$DEATHS,xlab = "DEATHS",main="")
par(opar)
M1aids=glm(DEATHS~log(TIME),data=AIDS,family=poisson())
summary(M1aids)
coefplot(M1aids)
require(arm)
coefplot(M1aids)
require(brinla)
data(crab, package="brinla")
str(crab)
require(MASS)
M1crab=glm.nb(SATELLITES~COLOR+SPINE+WIDTH,data=crab)
summary(M1aids)
summary(M1crab)
round(coef(summary(M1crab)),3)
x=5
y=2
z=x+y
z
x=c(2,5,4,3,4)
y=c(3,6,5,6,10)
log(x)
log(x,base=10)
log(x,base=2)
exp(x) #antilog
exp(log(x))# report orginal numbers
x=c(2,5,4,3,4)
y=c(3,6,5,6,10)
log(x)
log(x,base=10)
log(x,base=2)
exp(x) #antilog
exp(log(x))# report orginal numbers
x=c(2,5,4,3,4)
y=c(3,6,5,6,10)
log(x)
log(x,base=10)
log(x,base=2)
exp(x) #antilog
exp(log(x))# report orginal numbers
mean(x)
mean(y)
sd(x)
sd(y)
median(x)
quantile(x)
quantile(x,prob=c(.25,.5,.75)) #quartiles
min(x)
max(x)
#get length of the vector
length(x)
mean(x)
mean(y)
sd(x)
sd(y)
median(x)
quantile(x)
quantile(x,prob=c(.25,.5,.75)) #quartiles
min(x)
max(x)
#get length of the vector
length(x)
mean(x)
mean(y)
sd(x)
sd(y)
median(x)
quantile(x)
quantile(x,prob=c(.25,.5,.75)) #quartiles
min(x)
max(x)
#get length of the vector
length(x)
#Define a function for standard error of mean
sem=function(x) sd(x)/sqrt(length(x))
#dump it as a text file
dump("sem",file="sem.txt")
#source it
source("sem.txt")
# Define a function for coefficient of variation
cv=function(x) sd(x)/mean(x)*100
dump("cv",file="cv.txt")
source("cv.txt")
# let us assume height of 6 students in cm is
height=c(168,165,162,170,178,169)
dump("height",file="height.dat")
source("height.dat")
#get their sem and cv
sem(height)
cv(height)
x=c(2,5,4,3,4)
names(x)=c("A","B","C","D","E")
x
barplot(x)
#save it as png file
png("FigBarplot.png")
barplot(x)
barplot(x)
#save it as png file
png("FigBarplot.png")
barplot(x)
dev.off()
x=c(2,5,4,3,4)
names(x)=c("A","B","C","D","E")
x
barplot(x)
#save it as png file
png("FigBarplot.png")
barplot(x)
dev.off()
pdf("fig33.pdf")
barplot(x)
dev.off()
